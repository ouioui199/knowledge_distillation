# **KNOWLEDGE DISTILLATION PROJECT**
Project based on the paper [Distilling the Knowledge in a Neural Network](https://arxiv.org/pdf/1503.02531.pdf) of Geoffrey Hinton, Oriol Vinyals, Jeff Dean. The idea is to use a big artificial neural network and to distill its knowledges to a smaller one. Knowledge transfer increases performance of small models, enables the efficient usage in production phase where computation power is limited.

## **QUICK START**

## **DESCRIPTION** 